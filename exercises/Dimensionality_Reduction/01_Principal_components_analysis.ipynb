{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal components analysis (PCA)\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Understand how PCA is computed\n",
    "* Visualize a single-cell dataset with PCA\n",
    "* Understand how different biological axes of variation are separated into different components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user scprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Computing PCA on the UCI wine dataset\n",
    "\n",
    "#### How does PCA work?\n",
    "\n",
    "PCA related eigendecomposition methods are some of the most fundamental dimensionality reduction tools in data science. Many methods, including tSNE and PHATE, first reduce the data using PCA before performing further operations on the data. \n",
    "\n",
    "You can find many rigorous descriptions of the PCA algorithm online. Here, we will focus on the intutition. The goal of PCA is to identify a set of orthogonal dimensions (each of which is a linear combination of the input features) that explain the maximum variance in the data. These dimensions are called Principle Components. In the following figure, you can see data in two dimensions:\n",
    "\n",
    "<img src=\"https://krishnaswamylab.github.io/img/how_to_single_cell/PCA_original_data.png\" style=\"height: 25rem;\"/>\n",
    "\n",
    "This is a simple dataset where the data exists in two dimensions. The axis of maximum variance in this data is going to be some line that goes up and to the right. If you were to identify the first two principle components in this data they would look like the dashed grey lines in the following figure:\n",
    "\n",
    "<img src=\"https://krishnaswamylab.github.io/img/how_to_single_cell/PCA_PC1.png\" style=\"height: 35.35rem;\"/>\n",
    "\n",
    "PCA then projects the points onto these new axes. Above, we see the projection onto PC1 (the longest dashed line) for a handful of cells denoted by the red arrows. Note that the arrows are orthogonal (perpendicular) to PC1. This is the definition of projection. Below, you can see what the projection of the data onto the first principle component would look like. Here we're doing the simplest dimensionality reduction. We've taken the data from two dimensions to 1 dimension. Notice how some information is lost here. Some points are very close on PC1 that are far in the original data space. Some information loss is unavoidable when reducing dimensions. Notice that if we considered a second PC, we would get that information back.\n",
    "\n",
    "Visualization is a game of deciding what information you want to keep, and what you're comfortable throwing away. Here, we're looking at two dimensional data, but scRNA-seq usually has 20-30K data points. Some information will definitely be lost when considering only 1 or 2 principle components.\n",
    "\n",
    "**Note:** There exist as many PCs as there are original dimensions of the data, but we usually only consider the first 50-500 for single cell data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scprep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = sklearn.datasets.load_wine()\n",
    "\n",
    "# Access the numerical data from the wine Bunch\n",
    "data = wine['data']\n",
    "\n",
    "# Load data about the rows and columns\n",
    "feature_names = wine['feature_names']\n",
    "\n",
    "# Load cultivar information about each wine\n",
    "cultivars = np.array(['Cultivar{}'.format(cl) for cl in wine['target']])\n",
    "\n",
    "# Create nice names for each row\n",
    "wine_names = np.array(['Wine{}'.format(i) for i in range(data.shape[0])])\n",
    "\n",
    "# use the sklearn StandardScaler to scale to mean 0, variance 1\n",
    "data = sklearn.preprocessing.StandardScaler().fit_transform(data)\n",
    "\n",
    "# Gather all of this information into a DataFrame\n",
    "data = pd.DataFrame(data, columns=feature_names, index=wine_names)\n",
    "\n",
    "# Print the first 5 rows of the data, eq. to data[:5]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute PCA manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sample covariance matrix\n",
    "Sigma = np.cov(np.transpose(data))\n",
    "\n",
    "# compute the eigendecomposition\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(Sigma)\n",
    "\n",
    "# sort the eigenvectors in order of decreasing eigenvalue\n",
    "order = np.argsort(eigenvalues)[::-1] # [::-1] reverses the order of a list\n",
    "eigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:,order]\n",
    "\n",
    "# plot the eigenvalues\n",
    "plt.bar(np.arange(len(eigenvalues))+1, eigenvalues)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============\n",
    "# How many principal components do you think are meaningful in this dataset?\n",
    "n = \n",
    "# =============\n",
    "\n",
    "# take only the first n eigenvectors and eigenvalues\n",
    "eigenvectors, eigenvalues = eigenvectors[:,:n], eigenvalues[:n]\n",
    "\n",
    "# project the data onto the principal directions by matrix multiplication\n",
    "data_pca = data @ eigenvectors\n",
    "\n",
    "data_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cultivar = \"Cultivar0\" # alternative: \"Cultivar1\", \"Cultivar2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter(x=data_pca[0], y=data_pca[1],\n",
    "                    c=cultivars==my_cultivar, ticks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - pick through the first few principal components and see which best separate your chosen cultivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Use scprep.plot.scatter to plot different principal components\n",
    "scprep.plot.scatter(x=\n",
    "                    y=\n",
    "                    c=cultivars==my_cultivar, ticks=False)\n",
    "# ====================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Breakpoint_  - once you get here, please help those around you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Downloading the Retinal Bipolar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data from Google Drive\n",
    "scprep.io.download.download_google_drive(\"1bkOEkDJS1B8HeQUXtPHoo66qZiVK0ryC\",\n",
    "                                         \"shekhar_data.zip\")\n",
    "scprep.io.download.unzip(\"shekhar_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "data = scprep.io.load_mtx(\"shekhar_data/matrix.mtx\",\n",
    "                         cell_names=\"shekhar_data/cell_names.tsv\",\n",
    "                         gene_names=\"shekhar_data/gene_names.tsv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the cluster labels\n",
    "clusters = scprep.io.load_tsv(\"shekhar_data/shekhar_clusters.tsv\")\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "You should be familiar with the preprocessing workflow from earlier, but we'll walk through it step by step anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library size filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.plot_library_size(data, percentile=(20,80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are no cells with library size smaller than ~500. This dataset has already been filtered for library size, so we don't _need_ to do anything, but for speed and memory concerns we'll filter it a bit more aggressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, clusters = scprep.filter.filter_library_size(data, clusters, percentile=(20,80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library size normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scprep.normalize.library_size_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitochondrial DNA filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.plot_gene_set_expression(data, starts_with=\"mt-\", percentile=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a long tail of high mitochondrial expression. Since we normalized library size to 10,000, a mitochondrial expression of 8,000 means nearly the entire droplet was mitochondrial. We should remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, clusters = scprep.filter.filter_gene_set_expression(\n",
    "    data, clusters, starts_with=\"mt-\", keep_cells='below', percentile=80)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rare gene filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've removed some cells, it's likely that there are some genes with close to zero total counts. These are just a waste of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scprep.filter.filter_rare_genes(data, min_cells=10)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Square root transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scprep.transform.sqrt(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of many cell types, which were mostly identified as Amacrine cells, Muller Glia, Rod Bipolar cells, and many subtypes of Cone Bipolar cells in [Shekhar et. al, 2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5003425/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating celltypes by selecting appropriate plotting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['CELLTYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to separate out the Muller Glia cells from the rest of the dataset using a couple of known marker genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter(data['Apoe'], data['Glul'], c=clusters['CELLTYPE'],\n",
    "                    figsize=(10,4), legend_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Muller Glia cells are mostly separate from the rest, except for a smattering of cells labelled '-1'. These cells were not assigned a cluster in the original study, so let's see what the plot looks like without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter(data['Apoe'], data['Glul'], c=clusters['CELLTYPE'],\n",
    "                    mask=clusters['CELLTYPE'] != '-1',\n",
    "                    figsize=(10,4), legend_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the Muller Glia cells are relatively easy to identify using this combination of genes. But how should we choose such combinations of genes? With 20,000 to choose from, it's no easy feat. This is where PCA comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing PCA quickly\n",
    "\n",
    "There's a faster way to do PCA, and fortunately it's already implemented for us in `scikit-learn` and `scprep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we'll filter out those unlabeled cells\n",
    "data, clusters = scprep.select.select_rows(data, clusters, idx=clusters['CELLTYPE'] != '-1')\n",
    "\n",
    "import sklearn.decomposition\n",
    "pca_op = sklearn.decomposition.PCA(n_components=100) # we could also do scprep.reduce.pca(data, 100)\n",
    "data_pca = pca_op.fit_transform(scprep.utils.toarray(data))\n",
    "data_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we used `sklearn` here, `data_pca` is a numpy array, not a DataFrame. We could have avoided this conversion by using `scprep.reduce.pca`, but `sklearn` has some additional functionality that we will use later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the first two principal components\n",
    "\n",
    "Now we have computed the PCA, we can plot the first two directions to see how well our glial cells separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(data_pca, c=clusters['CELLTYPE'], figsize=(10,4),\n",
    "                      ticks=False, label_prefix='PC', legend_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, look at that! The glial cells separate perfectly from the Rod Bipolar cells (lime green) and the Cone Bipolar cells (most everything else).\n",
    "\n",
    "#### _Breakpoint_  - once you get here, please help those around you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Examining principal components\n",
    "\n",
    "Each principal component can be thought of as representing some latent state in the data. For example, we see that the first component largely separates glia from bipolar cells, and the second separates rod bipolar cells from cone bipolar cells. Now it's your turn - pick a cell type and try to find the best principal component to separate it from the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusters['CELLTYPE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# pick any named cell type\n",
    "my_celltype =\n",
    "# pick a principal component (a number >=1) to put on the x axis\n",
    "x_pc =\n",
    "# pick a principal component to put on the y axis\n",
    "y_pc =\n",
    "# ===============\n",
    "scprep.plot.scatter(data_pca[:,x_pc-1], data_pca[:,y_pc-1], c=clusters['CELLTYPE'] == my_celltype,\n",
    "                   ticks=False, xlabel='PC{}'.format(x_pc), ylabel='PC{}'.format(y_pc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining loadings associated with principal components\n",
    "\n",
    "The principal components are described by a linear combination of the original features, so we can use the coefficients of these principal directions (called \"loadings\") to understand which features are driving the separation. We'll do it here for the first two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_loadings = pd.DataFrame(pca_op.components_, columns=data.columns)\n",
    "pc_loadings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the top genes associated with PC1\n",
    "top_genes = np.abs(pc_loadings.loc[0]).sort_values(ascending=False)\n",
    "top_genes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter(x=data_pca[:,0], y=data_pca[:,1], c=data['Apoe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - find the top genes associated with PC2 and plot some of them on the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# find the top genes associated with PC2\n",
    "top_genes =\n",
    "# ==================\n",
    "top_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# plot the result with scprep\n",
    "scprep.plot.scatter(x=\n",
    "                    y=\n",
    "                    c=\n",
    "# =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Breakpoint_  - once you get here, please help those around you!\n",
    "\n",
    "### Exercise 4 - identify cell type markers with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============\n",
    "# examine the loadings of the principal component(s) that you used to identify your \n",
    "# cell type of choice and color the PCA plot by the top genes\n",
    "\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save data for later\n",
    "\n",
    "We'll save the preprocessed data file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"shekhar_data.pkl\")\n",
    "\n",
    "clusters.to_pickle(\"shekhar_clusters.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
