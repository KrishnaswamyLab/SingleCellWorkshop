{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear dimensionality reduction\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Visualize a single-cell dataset with t-SNE, UMAP and PHATE\n",
    "* Understand how important parameter tuning is to visualization\n",
    "* Understand how to compare the merits of different dimensionality reduction algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user scprep phate umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Retinal Bipolar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scprep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've done the preprocessing on this dataset before, we'll just download the preprocessed data from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.io.download.download_google_drive(\"1pRYn62SOmmJxwVU0sSW7eBagRL2RJmx0\", \"shekhar_data.pkl\")\n",
    "scprep.io.download.download_google_drive(\"1FlNktWuJCka3pXOvNIFfRitGluZy2ftt\", \"shekhar_clusters.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"shekhar_data.pkl\")\n",
    "clusters = pd.read_pickle(\"shekhar_clusters.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. t-SNE\n",
    "\n",
    "#### What is tSNE?\n",
    "t-SNE is the most popular visualization method for single cell RNA-sequencing data. The method was first introduced by Laurens van der Maaten in 2008 in the aptly named article [\"Visualizing High-Dimensional Data Using t-SNE\"](http://jmlr.org/papers/v9/vandermaaten08a.html). The goal of t-SNE is to produce a two or three dimensional embedding of a dataset that exists in many dimensions such that the embedding can be used for visualization.\n",
    "\n",
    "By embedding, we're talking about projecting the data from high dimensional space onto vectors in a smaller dimensional space.\n",
    "\n",
    "The way t-SNE does this is by minimizing the difference between neighborhood distances (i.e. distances from a cell to a set of close cells) in the original high dimensional space and the lower dimensional embedding space. t-SNE is an optimization problem where the algorithm iteratively learns a series of transformations such that each successive transformation better minimizes this difference between the high and low dimensional neighborhood distances. \n",
    "\n",
    "This approach preserves local structure in the data. Cells that are close in high dimensional space (i.e. have small Euclidean distances) will also be close in low dimensional space. However, it also means that global structure *will not* be preserved. This means that the distance between \"clusters\" in a t-SNE plot don't have any meaning.  In other words, the white-space on the graph has *no* interpretative value.\n",
    "\n",
    "\n",
    "#### How to use t-SNE effectively\n",
    "\n",
    "Unlike PCA, t-SNE has *hyperparameters* these are user-specified options that determine the output of t-SNE. Having hyperparameters isn't bad, but it is essential to understand what the hyperparameters are, what the effect of hyperpameter choices have on output, and how to select the best set of hyperparameters for a given research objective.\n",
    "\n",
    "In 2016, a group from Google Brain published great essay in Distill about [\"How to Use t-SNE Effectively\"](https://distill.pub/2016/misread-tsne/). In the article, they provide an interactive tool to explore the effect of various hyperparameters of t-SNE on various datasets.\n",
    "\n",
    "There are two main hyperparameters for t-SNE: **perplexity** and **learning rate** (sometimes called epsilon). Perplexity determines the \"neighborhood size\". Larger values of perplexity increase the number of points within the neighborhood. The reccomended range of t-SNE perplexity is roughly 5-50. Learning rate affects how quickly the algorithm \"stablilizes\". You probably don't need to change this, but should understand what it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of many cell types, which were mostly identified as Amacrine cells, Muller Glia, Rod Bipolar cells, and many subtypes of Cone Bipolar cells in [Shekhar et. al, 2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5003425/). We can plot the data using t-SNE, as was done in the original paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing dimensionality with PCA to speed up t-SNE\n",
    "\n",
    "t-SNE gets very slow with high-dimensional data. We can speed it up substantially by running PCA first to 100 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = scprep.reduce.pca(data, n_components=100, method='dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsampling to speed up t-SNE even more\n",
    "\n",
    "t-SNE is still slow even after PCA, so let's speed things up by using fewer points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca_subsample, clusters_subsample = scprep.select.subsample(data_pca, clusters, n=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running t-SNE\n",
    "\n",
    "tSNE is implemented in `scikit-learn`. t-SNE is a manifold learning algorithm and you can find the t-SNE operator at [`sklearn.manifold.TSNE`](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n",
    "\n",
    "We create a t-SNE operator and run it on data with the following syntax\n",
    "\n",
    "```python\n",
    "import sklearn.manifold\n",
    "tsne_op = sklearn.manifold.TSNE(n_components=2, perplexity=30)\n",
    "data_tsne = tsne_op.fit_transform(data)\n",
    "```\n",
    "\n",
    "**Note**: In the example below we are instantiating the `tsne_op` with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.manifold\n",
    "tsne_op = sklearn.manifold.TSNE()\n",
    "data_tsne = tsne_op.fit_transform(data_pca_subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting and interpreting t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(data_tsne, c=clusters_subsample['CELLTYPE'],\n",
    "                      figsize=(8,4), legend_anchor=(1,1),\n",
    "                      ticks=False, label_prefix='t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice? Is your favorite cell type nicely separated in this plot? How obvious is the distinction between the macro-level cell types of cone bipolar, rod bipolar, and glial cells?\n",
    "\n",
    "#### Exercise - run t-SNE with different `perplexity` parameters\n",
    "\n",
    "t-SNE's `perplexity` parameter describes the size of the neighborhood around each point. The authors recommend values between 5 and 100. Try a range of different values in and outside of this range and discuss the results with your group.\n",
    "\n",
    "*Note: be sure to use `data_pca_subsample`, as t-SNE can take a long time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# experiment with the perplexity parameter\n",
    "tsne_op = sklearn.manifold.TSNE(perplexity= ) # <-\n",
    "data_tsne =\n",
    "# =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(data_tsne, c=clusters_subsample['CELLTYPE'],\n",
    "                      figsize=(8,4), legend_anchor=(1,1), ticks=False, label_prefix='t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Breakpoint_  - once you get here, please help those around you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UMAP\n",
    "\n",
    "Even though UMAP is not a part of scikit-learn, the syntax for UMAP is identical to t-SNE: `umap.UMAP().fit_transform`. UMAP is relatively fast, so you won't need to use the subsampled data. We also don't need to do PCA beforehand, but since we've already done it we may as well use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_op = umap.UMAP()\n",
    "data_umap = umap_op.fit_transform(data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(data_umap, c=clusters_subsample['CELLTYPE'],\n",
    "                      figsize=(8,4), legend_anchor=(1,1), ticks=False, label_prefix='UMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice? Is your favorite cell type nicely separated in this plot? How obvious is the distinction between the macro-level cell types of cone bipolar, rod bipolar, and glial cells? How does this plot compare to t-SNE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - run UMAP with different `n_neighbors` and `min_dist` parameters\n",
    "\n",
    "UMAP's `n_neighbors` parameter describes the size of the neighborhood around each point. The `min_dist` parameter describes how tightly points can be packed together. The authors recommend values between 2 and 200 for `n_neighbors`, and between 0 and 0.99 for `min_dist`. Try a range of different values in and outside of these ranges and discuss the results with your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Choose different values for n_neighbors and min_dist, plotting with scprep\n",
    "umap_op =\n",
    "data_umap =\n",
    "scprep.plot.scatter2d(\n",
    "# ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Breakpoint_  - once you get here, please help those around you!\n",
    "\n",
    "## 4. PHATE\n",
    "\n",
    "### Exercise - perform PHATE and plot the results\n",
    "\n",
    "The syntax for PHATE is identical to UMAP and t-SNE: `phate.PHATE().fit_transform`. PHATE is relatively fast, so you won't need to use the subsampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phate\n",
    "phate_op = phate.PHATE()\n",
    "data_phate = phate_op.fit_transform(data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(data_phate, c=clusters_subsample['CELLTYPE'],\n",
    "                      figsize=(8,4), legend_anchor=(1,1), ticks=False, label_prefix='PHATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice? Is your favorite cell type nicely separated in this plot? How obvious is the distinction between the macro-level cell types of cone bipolar, rod bipolar, and glial cells? How does this plot compare to t-SNE and UMAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - run PHATE with different `knn` and `t` parameters\n",
    "\n",
    "UMAP's `knn` parameter describes the size of the neighborhood around each point. The `t` parameter describes how much denoising is performed. We recommend values between 2 and 100 for `n_neighbors`, and between 2 and 150 for `t`. Try a range of different values in and outside of these ranges and discuss the results with your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Choose different values for knn and y, plotting with scprep\n",
    "phate_op =\n",
    "data_phate =\n",
    "scprep.plot.scatter2d(\n",
    "# ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion \n",
    "\n",
    "In groups, discuss the following questions:\n",
    "1. In a dataset with clusters, how well does each method perform?\n",
    "2. How might you determine which method is closest to the ground truth?\n",
    "3. Which parameters are the most similar between methods?\n",
    "4. Which method is the most / least sensitive to parameter selection?\n",
    "5. If you run the same method with the same parameters multiple times, do you always get the same result?\n",
    "\n",
    "**Note Dan/Scott**: In one of the earlier clustering notebooks, we did more formal method of clustering efficiency, can we ask the students to actually do that as an exercise, if it is not too complicated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
